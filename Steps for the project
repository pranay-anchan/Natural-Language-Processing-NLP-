# 2.0 Method  
## 2.1 Tools to be used 
 To perform the necessary pdf to text extraction the following python packages are used: PyPDF2, textract, nltk, eazymind, pandas, bert_summarizer. For the abstractive sentence summarization the following python packages are used: torch, PyCoreNLP, argparse, numpy, spaCy, tensorflow, sci-kit learn, and pyrouge, eazymind.  Additionally, for computational resources, a google colab jupyter notebook is created to process the text for this project and to run the different abstract models. Note, the eazymind4 API only works with max 5 sentences (paragraph). The following link connects to the notebook and a copy of the jupyter notebook will be provided with this report: https://colab.research.google.com/drive/1oQdfQtTbeKJe2xggpWdR_j98ZJVDFUPo?authuser=1 #scrollTo=Cjczk---l_ZN 
## 2.2 Data  
 
###2.2.1 PDFs

The PDFs used are selected randomly and cover two separate types of documents. The first is a cybersecurity report from Oct 2019.  It contains text, images, and tables.  The second pdf is the book Pride and Prejudice taken from the gutenberg files and converted into a .pdf. The third is this report, which will go through the same processes as the other two.  

### 2.2.2 Training / Testing / Validation Data

The CNN-Daily5 data set is widely used across multiple deep learning NLP tasks(Liu et al., 2019).  It is likewise used for training, validation, and testing of a deep learning model which will generate abstractive summaries.  The data is preprocessed as each .story is placed in a text field for the body text and a summary field for the summary. This dataset is used in two pointergenerator and sentence parser summarizer model.  Additionally, the gigaword6 dataset and the newsroom7 dataset are used in the sentence parser summarizer model8. 

## 2.3 Experimental Process 
This section will explain the steps taken to perform the experiment with the various models. 

### 2.3.1 PDF to Text

Read in a pdf and extract the text. This operation utilized PyPDF2 and textract. 
A function was built to extract the text if the pdf is a vectorized pdf with PyPDF2 or if a picture then textract is used.  The text is then placed in a pandas dataframe where several regex filters are run to                                                
 4 http://eazymind.herokuapp.com/arabic_sum/ 5 https://github.com/abisee/cnn-dailymail 6 https://catalog.ldc.upenn.edu/LDC2012T21 7 https://summari.es/ 8 https://github.com/ucfnlp/joint-parse-n-summarize 
 clean the text. The cleaning includes removing symbols, http links, and other non UTF-8 encodings.  Additionally, cleaning will remove extra white space and any image related content generated by the pdf to text conversion. The text in the pandas dataframe is then converted into a string.  The pdf to text function may be viewed in image5. 

### 2.3.2 Text to Extractive Summarization (BERT) 

The cleaned text (as a string) is then passed through the BERT9 summarization model with a limit on sentences being a minimum of 100 length. The limit of 100 is based on characters and was generated to remove all sentences with length less than 100 characters.  This allows for longer sentences with more context to remain while simultaneously limiting text with little content. The summarized text is then combined back into a string and stored in a .txt file.  

### 2.3.3 EasyMind Pointer-Generator  

The easymind pointer-generator model was developed by github user @theamrzaki by combining several open-source abstractive techniques. The summarized text is passed through the model, which often fails.  When the model receives a word or character that is not UTF-8 encoded, then an error occurs.  Likewise, the model is trained on the CNNDaily dataset, so model does not contain more technical terms found in the cybersecurity report.  To see a result of this model, see the results section below.   

### 2.3.5 TextRank 

Textrank is an automatic summarization model which relies on term frequencyâ€“inverse document frequency (tf-idf) weights of tokenized words and tokenized sentences.  The model produced by SummaNLP may be used to generate summaries of text.  The summarized text from BERT is passed through the textRank summarizer and the results are posted in the results section.    
### 2.3.6 Joint-Parse-n-Summarizer 

The Joint Parsing and Generation for Abstractive Summarization10 model is developed by Kaiqiang Song, a PhD student at the University of Central Florida.  The model aims to generate an abstractive summarization for sentences a varying length.  The same summarization text is passed through the model and the results are seen in the next section.   
 
